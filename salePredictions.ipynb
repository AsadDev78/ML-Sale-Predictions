{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b222ec6c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "# 1. Data Ingestion & Merging\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "# Load CSV files (Ensure these are in your working directory)\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_stores = pd.read_csv('stores.csv')\n",
    "df_oil = pd.read_csv('oil.csv')\n",
    "df_holidays = pd.read_csv('holidays_events.csv')\n",
    "\n",
    "\n",
    "# Convert date columns to datetime objects\n",
    "df_train['date'] = pd.to_datetime(df_train['date'])\n",
    "df_oil['date'] = pd.to_datetime(df_oil['date'])\n",
    "\n",
    "\n",
    "# Merge data to create one master dataframe\n",
    "# Merge with Oil prices\n",
    "df = pd.merge(df_train, df_oil, on='date', how='left')\n",
    "# Merge with Stores data\n",
    "df = pd.merge(df, df_stores, on='store_nbr', how='left')\n",
    "\n",
    "# We filter for Store Number 1 to make this run efficiently on CPU.\n",
    "df = df[df['store_nbr'] == 1].copy()\n",
    "\n",
    "# Imputation: Fill missing oil values (Forward Fill then Backward Fill)\n",
    "df['dcoilwtico'] = df['dcoilwtico'].ffill().bfill()\n",
    "\n",
    "print(f\"Data Loaded. Shape: {df.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "# 2.1 Sales over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "df.groupby('date')['sales'].sum().plot(color='purple')\n",
    "plt.title('Total Sales Over Time (Store 1)')\n",
    "plt.ylabel('Sales')\n",
    "plt.xlabel('Date')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show() #\n",
    "\n",
    "# 2.2 Distribution of Sales\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(df['sales'], bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Sales Target')\n",
    "plt.xlabel('Sales')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# 2.3 Sales by Product Family\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_families = df.groupby('family')['sales'].sum().sort_values(ascending=False).head(10)\n",
    "sns.barplot(x=top_families.values, y=top_families.index, palette='viridis')\n",
    "plt.title('Top 10 Product Families by Sales')\n",
    "plt.show()\n",
    "\n",
    "# 2.4 Correlation Matrix\n",
    "# Select only numeric columns for correlation\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(numeric_df.corr(), annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# 2. Preprocessing & Feature Engineering\n",
    "\n",
    "# Extract Date Features (Crucial for Time Series)\n",
    "df['day'] = df['date'].dt.day\n",
    "df['month'] = df['date'].dt.month\n",
    "df['year'] = df['date'].dt.year\n",
    "df['dayofweek'] = df['date'].dt.dayofweek\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(['sales', 'id', 'date'], axis=1)\n",
    "y = df['sales']\n",
    "\n",
    "# Identify column types\n",
    "categorical_features = ['family', 'city', 'state', 'type', 'cluster']\n",
    "numerical_features = ['onpromotion', 'dcoilwtico', 'day', 'month', 'year', 'dayofweek']\n",
    "\n",
    "# Create Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit and Transform data\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Convert to dense array (Required for Neural Networks)\n",
    "if hasattr(X_processed, 'toarray'):\n",
    "    X_processed = X_processed.toarray()\n",
    "\n",
    "# Data Splitting (Train / Validation / Test)\n",
    "# Splitting 80% Train, 20% Test\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# 3A. ANN BASELINE MODEL (REQUIRED)\n",
    "\n",
    "ann_model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_raw.shape[1],)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "ann_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "print(\"Training ANN Model...\")\n",
    "history_ann = ann_model.fit(\n",
    "    X_train_raw, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ANN Evaluation\n",
    "ann_pred = ann_model.predict(X_test_raw)\n",
    "\n",
    "ann_mae = mean_absolute_error(y_test, ann_pred)\n",
    "ann_rmse = np.sqrt(mean_squared_error(y_test, ann_pred))\n",
    "\n",
    "print(\"\\n--- ANN Evaluation ---\")\n",
    "print(f\"ANN MAE : {ann_mae:.2f}\")\n",
    "print(f\"ANN RMSE: {ann_rmse:.2f}\")\n",
    "\n",
    "# 4. Evaluation & Visualization\n",
    "\n",
    "# Plot Loss Curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training MSE', color='blue')\n",
    "plt.plot(history.history['val_loss'], label='Validation MSE', color='orange')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
